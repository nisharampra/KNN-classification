{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbours classification\n",
    "## Instructions:\n",
    "* Go through the notebook and complete the tasks. \n",
    "* Make sure you understand the examples given. If you need help, refer to the Essential readings or the documentation link provided, or go to the discussion forum. \n",
    "* When a question allows a free-form answer (e.g. what do you observe?), create a new markdown cell below and answer the question in the notebook. \n",
    "* Save your notebooks when you are done.\n",
    " \n",
    "**Task 1:**\n",
    "Run the cell below to load our data. Notice the last line, where we add some random Gaussian noise to our data to make the task more challenging (data in real life usually contains some form of noise).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#view a description of the dataset \n",
    "print(iris.DESCR)\n",
    "\n",
    "#Set X a samples times features matrix, Y equal to the targets\n",
    "X=iris.data \n",
    "y=iris.target \n",
    "\n",
    "\n",
    "#we add some random noise to our data to make the task more challenging\n",
    "X=X+np.random.normal(0,0.4,X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2:**\n",
    "1.\tHow many data samples do we have?\n",
    "2.\tPrint the value below using shape on ```X``` appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 150\n"
     ]
    }
   ],
   "source": [
    "#Enter code here\n",
    "# Print the number of samples using the shape of X\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:**\n",
    "1.\tHow many features do we have?\n",
    "2.\tPrint the value below using shape on ```X``` appropriately. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4\n"
     ]
    }
   ],
   "source": [
    "#Enter code here\n",
    "# Print the number of features using the shape of X\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4:**\n",
    "1.\tHow many classes do we have?\n",
    "2.\tPrint the value below using ```np.unique``` appropriately. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "#Enter code here\n",
    "# Print the number of unique classes using np.unique\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5:**\n",
    "1.\tHow many samples do we have that belong to class 1?\n",
    "2.\tPrint this in the cell below using the ```np.where``` function appropriately. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in class 1: 50\n"
     ]
    }
   ],
   "source": [
    "#Enter code here\n",
    "# Print the number of samples belonging to class 1 using np.where\n",
    "class_1_samples = np.where(y == 1)[0].shape[0]\n",
    "print(f\"Number of samples in class 1: {class_1_samples}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6:** \n",
    "\n",
    "Assume we want to generate a list of shuffled indices of our data. Use the function ```numpy.random.permutation``` to do that. In the cell below, you can already see how to create a list of indices that is not shuffled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "Shuffled indices: [  9 111  57  65  47 118 141  71 143 126 106  29  86  39 110  22 115  94\n",
      "  56  54  26  44   7 129  85  28  66  19  37 122  43  30  75 132 112 104\n",
      "  64  77 138  69  91 139  46  12  23  14   5  87  68 127  93   4 121  20\n",
      " 100  83  51 130 116  95  99  92  62 136  50  63  81  74   6  25 103 147\n",
      "  61 124  35 144 142 113 125  17  78  49 119 105  36   0  52   2 146  67\n",
      " 140   3 131  82  34 102  16 145  79  53  72  33 149   1  18  76  10  13\n",
      "  27 128  21  98  32  42 101  59 135  41 148 123 137 114 108  40  58  84\n",
      "  90  88 109  11  70 134   8  55  97  89 133  80  45  15  31 117  38  60\n",
      "  48  73  24 120 107  96]\n"
     ]
    }
   ],
   "source": [
    "L=list(range(X.shape[0]))\n",
    "print(L)\n",
    "#Enter code here\n",
    "# Create a list of indices and shuffle them using np.random.permutation\n",
    "L = np.random.permutation(X.shape[0])\n",
    "print(f\"Shuffled indices: {L}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7:**\n",
    "Here is an example of using the k-NN classifier. We split our data to training and testing (with a 0.2 percentage for our test data), fit on the training data, test on the testing data. \n",
    "Go through the code and make sure you understand it.\n",
    "Now do the same for the next cell, which prints the confusion matrix and the total accuracy. \n",
    "You can find some documentation to help you here: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html. \n",
    "Note that for this lab, we use the Euclidean distance along with 10 neighbours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 2 2 2 0 1 0 2 0 0 1 0 2 2 2 2 1 0 0 1 2 0 1 2 2]\n",
      "[1 1 1 1 0 1 2 1 2 0 1 0 1 0 0 1 0 2 2 2 1 1 0 0 2 2 0 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#split to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#define knn classifier, with 5 neighbors and use the euclidian distance\n",
    "knn=KNeighborsClassifier(n_neighbors=10, metric='euclidean')\n",
    "#define training and testing data, fit the classifier\n",
    "knn.fit(X_train,y_train)\n",
    "#predict values for test data based on training data\n",
    "y_pred=knn.predict(X_test)\n",
    "#print values\n",
    "print(y_test) # true values\n",
    "print(y_pred) # predicted values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 0 0]\n",
      " [0 8 2]\n",
      " [0 4 7]]\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 8:**\n",
    "Write your <b>own</b> functions that return the confusion matrix given the true and predicted labels, as well as the accuracy. To do so, fill in the code in the next two cells. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 0 0]\n",
      " [0 8 2]\n",
      " [0 4 7]]\n"
     ]
    }
   ],
   "source": [
    "def myConfMat(y_test, y_pred, classno):\n",
    "    # Create an empty confusion matrix\n",
    "    C = np.zeros((classno, classno), dtype=int)\n",
    "\n",
    "    # Populate the confusion matrix\n",
    "    for i in range(len(y_test)):\n",
    "        C[y_test[i], y_pred[i]] += 1\n",
    "    \n",
    "    return C\n",
    "\n",
    "# Calculate and print the custom confusion matrix\n",
    "print(myConfMat(y_test, y_pred, len(np.unique(y))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "def myAccuracy(y_test, y_pred):\n",
    "    # Calculate accuracy as the ratio of correct predictions to total predictions\n",
    "    correct = np.sum(y_test == y_pred)\n",
    "    total = len(y_test)\n",
    "    return correct / total\n",
    "\n",
    "# Calculate and print the custom accuracy\n",
    "print(f\"Custom Accuracy: {myAccuracy(y_test, y_pred)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional task:**</span> Write your own functions to calculate class-relative precision and recall. Compare these to the sklearn functions ``precision_score`` and ``recall_score`` on your y_test and y_pred values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Precision: [1.         0.66666667 0.77777778]\n"
     ]
    }
   ],
   "source": [
    "def myPrecision(y_true, y_pred):\n",
    "    classes = np.unique(y_true)\n",
    "    precision = np.zeros(classes.shape)\n",
    "\n",
    "    for class_label in classes:\n",
    "        true_positives = np.sum((y_true == class_label) & (y_pred == class_label))\n",
    "        predicted_positives = np.sum(y_pred == class_label)\n",
    "        if predicted_positives > 0:\n",
    "            precision[class_label] = true_positives / predicted_positives\n",
    "        else:\n",
    "            precision[class_label] = 0.0\n",
    "            \n",
    "    return precision\n",
    "\n",
    "# Calculate and print custom precision\n",
    "print(f\"Custom Precision: {myPrecision(y_test, y_pred)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Recall: [1.         0.8        0.63636364]\n"
     ]
    }
   ],
   "source": [
    "def myRecall(y_true, y_pred):\n",
    "    classes = np.unique(y_true)\n",
    "    recall = np.zeros(classes.shape)\n",
    "\n",
    "    for class_label in classes:\n",
    "        true_positives = np.sum((y_true == class_label) & (y_pred == class_label))\n",
    "        actual_positives = np.sum(y_true == class_label)\n",
    "        if actual_positives > 0:\n",
    "            recall[class_label] = true_positives / actual_positives\n",
    "        else:\n",
    "            recall[class_label] = 0.0\n",
    "    \n",
    "    return recall\n",
    "\n",
    "# Calculate and print custom recall\n",
    "print(f\"Custom Recall: {myRecall(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
